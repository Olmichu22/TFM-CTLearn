# Training performed with CTLearn version 0.8.0.post5 and TensorFlow version 2.14.1.
Data:
  event_info:
  - true_shower_primary_id
  file_list:
  - ../data/gamma_theta_16.087_az_108.090_runs1-2.r1.dl1.h5
  - ../data/gamma_theta_16.087_az_108.090_runs3-4.r1.dl1.h5
  - ../data/proton_theta_16.087_az_108.090_runs1-2.r1.dl1.h5
  - ../data/proton_theta_16.087_az_108.090_runs3-4.r1.dl1.h5
  - ../data/proton_theta_16.087_az_108.090_runs5-6.r1.dl1.h5
  image_settings:
    image_channels:
    - image
    - peak_time
  mapping_settings:
    camera_types:
    - LSTCam
    mapping_method:
      CHEC: oversampling
      DigiCam: bilinear_interpolation
      FlashCam: bilinear_interpolation
      LSTCam: bilinear_interpolation
      LSTSiPMCam: bilinear_interpolation
      MAGICCam: bilinear_interpolation
      NectarCam: bilinear_interpolation
      SCTCam: oversampling
    padding:
      CHEC: 0
      DigiCam: 2
      FlashCam: 2
      LSTCam: 2
      LSTSiPMCam: 2
      MAGICCam: 2
      NectarCam: 2
      SCTCam: 0
  mode: mono
  parameter_selection:
  - col_name: hillas_intensity
    min_value: 50.0
  selected_telescope_types:
  - LST_LST_LSTCam
  shuffle: true
  transforms: []
Input:
  batch_size_per_worker: 24
  stack_telescope_images: false
Logging:
  model_directory: output
Model:
  backbone:
    function: single_cnn_model
    module: single_cnn
  head:
    function: standard_head
    module: head
  image_engine:
    function: stacked_res_blocks
    module: resnet
  name: ThinResNet
Model Parameters:
  attention:
    mechanism: Squeeze-and-Excitation
    ratio: 16
  resnet:
    stacked_res_blocks:
      architecture:
      - blocks: 2
        filters: 48
      - blocks: 3
        filters: 96
      - blocks: 3
        filters: 128
      - blocks: 3
        filters: 256
      residual_block: bottleneck
  standard_head:
    direction:
      fc_head:
      - 512
      - 256
      weight: 1.0
    energy:
      fc_head:
      - 512
      - 256
      weight: 1.0
    type:
      fc_head:
      - 512
      - 256
      weight: 1.0
Reco:
- type
Training:
  adam_epsilon: 1.0e-08
  base_learning_rate: 0.0001
  lr_reducing_factor: 0.5
  lr_reducing_mindelta: 0.01
  lr_reducing_minlr: 1.0e-05
  lr_reducing_patience: 5
  num_epochs: 15
  optimizer: Adam
  validation_split: 0.1
  verbose: 2
  workers: 1
